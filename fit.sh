python3 run_lm_finetuning.py \
    --output_dir=output \
    --model_type=gpt2 \
    --model_name_or_path=gpt2-large \
    --do_train \
    --train_data_file=train_harry.txt \
    --per_gpu_train_batch_size 1 \
    --save_steps=20000 \
    --logging_steps=1 \
    --fp16 \
    --fp16_opt_level O1 \
    --warmup_samples 16000 \
    --learning_rate 5e-5 \
    --do_eval \
    --evaluate_during_training \
    --eval_steps 1000 \
    --eval_data_file=val_harry.txt \
    --unfreeze_level 0 \
    --no_cuda